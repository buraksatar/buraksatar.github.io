---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a final year PhD candidate at CCDS, NTU, Singapore, under the SINGA scholarship by I2R, A\*STAR. My PhD work is on **Towards Semantic, Debiased and Moment Video Retrieval with Multi-modal Features** under [Prof. Joo Hwee Lim](https://scholar.google.com/citations?user=BjEDX4EAAAAJ&hl=en), [Dr Hongyuan Zhu](https://hongyuanzhu.github.io/) and [Prof. Hanwang Zhang](https://mreallab.github.io/people.html). During my PhD, I visited the University of Bristol, UK, under [Prof. Michael Wray](https://mwray.github.io/) in Dima Damen's group. I did my MSc under [Prof. Ahmet Emir Dirik](https://scholar.google.com/citations?user=cfgcBIEAAAAJ&hl=tr) on vehicle detection. My working experiences vary from a start-up in Istanbul to Turkish Airlines Technology and an internship at the University of Valencia. I also advised two award-winning start-ups based in London and Istanbul. **I am considering the opportunities for the next step**.

Recent News
======
* 07/2024: Expected date to submit the PhD Thesis.
* 07/2024: Our recent work is under review.

<span style="color:blue"> -------------------------------------------------------------------------------------------------- </span>

Publications
======

## #PhD Research 3: Multimodal and Generative Video/Moment Retrieval

**Video Corpus Moment Retrieval in Long Ego-centric Videos with LLM and Audio Fusion** \\
**Burak Satar**, Joo Hwee Lim, Hanwang Zhang, M Furkan Ilaslan, Hongyuan Zhu, Michael Wray \\
Under review 

**VG-TVP: Multimodal Procedural Planning via Visually Grounded Text-Video Prompting** \\
M Furkan Ilaslan, Ali Koksal, Kevin Qinghong Lin, **Burak Satar**, Mike Zheng Shou, Qianli Xu \\
Under review 

## #PhD Research 2: Debiased Text-to-Video Retrieval

<img src="https://buraksatar.github.io/images/scm_camready.png" alt="Structural Causal Model" width="400"/> \\
**Towards Debiasing Frame Length Bias in Text-Video Retrieval via Causal Intervention** \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
BMVC 2023 Full Paper, (Poster presentation) \\
[[arXiv](https://arxiv.org/abs/2309.09311)] [[YouTube Ppt](https://youtu.be/aMhNvTCkT8Y)] [[Poster](https://drive.google.com/file/d/10aXgkCl4PowFelEOyxJp4X90cTtub6Pt/view?usp=sharing)] [[Project Page](https://buraksatar.github.io/FrameLengthBias/)]

<img src="https://buraksatar.github.io/images/cvpr'23_workshop.png" alt="An Overview of Challenges" width="400"/> \\
**An Overview of Challenges in Egocentric Text-Video Retrieval** \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
CVPR Workshop 2023, [Joint Ego4d/EPIC Workshop](https://sites.google.com/view/ego4d-epic-cvpr2023-workshop/) (Oral presentation) \\
[[Extended Abstract](https://arxiv.org/abs/2306.04345)] [[YouTube Ppt](https://youtu.be/XnUMScoOPvM)]

## #PhD Research 1: Semantic Text-to-Video Retrieval

**Semantic Role Aware Correlation Transformer for Text to Video Retrieval** \\
**Burak Satar**, Zhu Hongyuan, Xavier Bresson, Joo-Hwee Lim \\
ICIP 2021 Full Paper (Oral presentation) and [ICCV Workshop 2021](https://sites.google.com/view/srvu-iccv21-workshop/papers?authuser=0) (Oral presentation)\\
[[arXiv](https://arxiv.org/abs/2206.12849)] [[(pseudo)Code](https://github.com/buraksatar/RoME_video_retrieval)] [[YouTube Ppt](https://www.youtube.com/watch?v=M7dHgv8fIkU)]

<img src="https://buraksatar.github.io/images/icip'21.png" alt="Overview of our model on text-to-video retrieval" width="400"/> \\

**RoME: Role-aware Mixture-of-Expert Transformer for Text-to-Video Retrieval** \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
[[arXiv 2022 Preprint](https://arxiv.org/abs/2206.12845)] [[(pseudo)Code](https://github.com/buraksatar/RoME_video_retrieval)]

<img src="https://buraksatar.github.io/images/cvpr'22_workshop.png" alt="Architecture" width="300"/> \\

(âœ… 3rd Place Award) **Exploiting Semantic Role Contextualized Video Features**\\
**for Multi-Instance Video Retrieval**  \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
CVPR Workshop 2022, Epic-Kitchens-100 MIR Challenge under [Joint Ego4d/EPIC Workshop](https://sites.google.com/view/cvpr2022w-ego4d-epic/)  \\
[[Technical Report](https://arxiv.org/abs/2206.14381)] [[(pseudo)Code](https://github.com/buraksatar/RoME_video_retrieval)]

## #MSc Research

<img src="https://buraksatar.github.io/images/icann'18.png" alt="Detection and classification method" width="250"/> \\
**Deep Learning Based Vehicle Make-Model Classification** \\
**Burak Satar**, Ahmet Emir Dirik \\
ICANN 2018 Full Paper (Oral presentation) \\
[[arXiv](https://arxiv.org/abs/1809.00953)] [[Code](https://github.com/buraksatar/car-detection-model-prediction)]

<span style="color:blue"> -------------------------------------------------------------------------------------------------- </span>

Previous News
======
* 05/2024: Volunteered at ACM Web Conference.
* 10/2023: Visited [MaVi Research Group](https://uob-mavi.github.io/), University of Bristol, for three months under the supervision of [Dr Michael Wray](https://mwray.github.io/) on video corpus moment retrieval.
* 05/2023: A poster presentation at [Singapore Vision Day](https://www.comp.nus.edu.sg/~leegh/svd/) at NUS.
* 07/2022: Attended [CIFAR DLRL Summer School](https://dlrl.ca/).
* 06/2022: 3rd Place Award in EPIC-Kitchens [Multi-Instance Retrieval Challenge](https://epic-kitchens.github.io/2022), CVPR.
* 06/2022: Became a finalist in the [Three Minute Thesis](https://entuedu-my.sharepoint.com/:i:/g/personal/burak001_e_ntu_edu_sg/EQ0kK2wvx_NCozw2x-2rvDEBPNcEA507M4YHG-aEzVZgTA?e=ZuLwTs) (3MT) @ NTU, representing CCDS.  
* 01/2022: Successfully passed my Qualification Exam (QE).
* 12/2021: Volunteered in NeurIPS.
* 07/2021: Attended [PAISS AI Summer School](https://project.inria.fr/paiss/), and presented a poster.
* 2020: Started my PhD journey in the College of Computing and Data Science(CCDS), NTU
* 08/2018: Successfully defended my MSc thesis. 
* 06/2018: Got [student travel award](https://e-nns.org/student-awards/winners-2018/) by European Neural Network Society to attend ICANN.
