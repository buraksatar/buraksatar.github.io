---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a Research Scientist at Singapore Management University (SMU), working under the guidance of [Prof Chong-Wah Ngo](https://scholar.google.com/citations?user=HM39HrUAAAAJ&hl=en). My focus is on culturally aware multimodal Vision-Language Models (VLMs) with reasoning capabilities specific to Southeast Asia.

I obtained my PhD from the College of Computing and Data Science (CCDS) at Nanyang Technological University (NTU) in Singapore, supported by the SINGA scholarship from the Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A\*STAR). My doctoral research focused on **Towards Semantic, Debiased and Moment Video Retrieval with Multi-modal Features** conducted under the supervision of [Prof. Joo Hwee Lim](https://scholar.google.com/citations?user=BjEDX4EAAAAJ&hl=en), [Dr Hongyuan Zhu](https://hongyuanzhu.github.io/) and [Prof. Hanwang Zhang](https://scholar.google.com.sg/citations?user=YG0DFyYAAAAJ&hl=en&inst=14102473421921925766). During my PhD studies, I had the opportunity to visit the University of Bristol, in the UK, collaborating with [Prof. Michael Wray](https://scholar.google.com/citations?user=gFQcKZMAAAAJ&hl=en&oi=ao&inst=14102473421921925766) in Dima Damen's research group. I completed my Master’s degree under the guidance of [Prof. Ahmet Emir Dirik](https://scholar.google.com/citations?user=cfgcBIEAAAAJ&hl=tr), specializing in vehicle detection. My professional experiences span a range of roles, including work at a start-up in Istanbul, Turkish Airlines Technology, and an internship at the University of Valencia. Additionally, I have provided advisory support to two award-winning start-ups located in London and Istanbul.

Recent News
======
* 08/2025: Another paper is submitted.
* 08/2025: A paper is accepted to EMNLP 2025!
* 03/2025: Started to work as a Research Scientist at SMU.

<span style="color:blue"> -------------------------------------------------------------------------------------------------- </span>

Publications
======
# Research during Post-Doctoral Work

**Seeing Culture: A Benchmark for Visual Reasoning and Grounding** \\
**Burak Satar**, Zhixin Ma, Patrick Amadeus Irawan, Wilfried Ariel Mulyawan, Jing Jiang, Ee-Peng Lim, Chong-Wah Ngo \\
EMNLP 2025 Main Conference \\
[Project Website](https://seeingculture-benchmark.github.io/)[arXiv][Code](https://github.com/buraksatar/seeingculture-benchmark)[Dataset](https://huggingface.co/datasets/Multimedia-SMU/seeingculture-benchmark) (links to be updated by 19 Sep)

**Title to be updated** \\
Zhixin Ma, **Burak Satar**, Patrick Amadeus Irawan, Wilfried Ariel Mulyawan, Phuong Anh Nguyen, Chong-Wah Ngo \\
Under review \\
[arXiv] (link to be updated)

# Research during Doctoral Study
## PhD Research Topic 3: Multimodal and Generative Video/Moment Retrieval

**Video Corpus Moment Retrieval in Long Ego-centric Videos with LLM and Audio Fusion** \\
**Burak Satar**, Joo Hwee Lim, Hanwang Zhang, M Furkan Ilaslan, Hongyuan Zhu, Michael Wray \\
(Under development)

**VG-TVP: Multimodal Procedural Planning via Visually Grounded Text-Video Prompting** \\
M Furkan Ilaslan, Ali Koksal, Kevin Qinghong Lin, **Burak Satar**, Mike Zheng Shou, Qianli Xu \\
AAAI 2025 Full Paper
[[arXiv](https://arxiv.org/abs/2412.11621)] [[Dataset Link](https://drive.google.com/drive/folders/1-Lka5F-Dh-Fz6CwHDJYjUqieXlt2GCR6)] [[Github](https://github.com/mfurkanilaslan/VG-TVP?tab=readme-ov-file)]

## PhD Research Topic 2: Debiased Text-to-Video Retrieval

<img src="https://buraksatar.github.io/images/scm_camready.png" alt="Structural Causal Model" width="400"/> \\
**Towards Debiasing Frame Length Bias in Text-Video Retrieval via Causal Intervention** \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
BMVC 2023 Full Paper, (Poster presentation) \\
[[arXiv](https://arxiv.org/abs/2309.09311)] [[YouTube Ppt](https://youtu.be/aMhNvTCkT8Y)] [[Poster](https://drive.google.com/file/d/10aXgkCl4PowFelEOyxJp4X90cTtub6Pt/view?usp=sharing)] [[Project Page](https://buraksatar.github.io/FrameLengthBias/)]

<img src="https://buraksatar.github.io/images/cvpr'23_workshop.png" alt="An Overview of Challenges" width="400"/> \\
**An Overview of Challenges in Egocentric Text-Video Retrieval** \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
CVPR Workshop 2023, [Joint Ego4d/EPIC Workshop](https://sites.google.com/view/ego4d-epic-cvpr2023-workshop/) (Oral presentation) \\
[[Extended Abstract](https://arxiv.org/abs/2306.04345)] [[YouTube Ppt](https://youtu.be/XnUMScoOPvM)]

## PhD Research Topic 1: Semantic Text-to-Video Retrieval

(✅ 3rd Place Award) **Exploiting Semantic Role Contextualized Video Features**\\
**for Multi-Instance Video Retrieval**  \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
CVPR Workshop 2022, Epic-Kitchens-100 MIR Challenge under [Joint Ego4d/EPIC Workshop](https://sites.google.com/view/cvpr2022w-ego4d-epic/)  \\
[[Technical Report](https://arxiv.org/abs/2206.14381)] [[(pseudo)Code](https://github.com/buraksatar/RoME_video_retrieval)]

<img src="https://buraksatar.github.io/images/cvpr'22_workshop.png" alt="Architecture" width="300"/>

**RoME: Role-aware Mixture-of-Expert Transformer for Text-to-Video Retrieval** \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
[[arXiv 2022 Preprint](https://arxiv.org/abs/2206.12845)] [[(pseudo)Code](https://github.com/buraksatar/RoME_video_retrieval)]

<img src="https://buraksatar.github.io/images/icip'21.png" alt="Overview of our model on text-to-video retrieval" width="400"/>

**Semantic Role Aware Correlation Transformer for Text to Video Retrieval** \\
**Burak Satar**, Zhu Hongyuan, Xavier Bresson, Joo-Hwee Lim \\
ICIP 2021 Full Paper (Oral presentation) and [ICCV Workshop 2021](https://sites.google.com/view/srvu-iccv21-workshop/papers?authuser=0) (Oral presentation)\\
[[arXiv](https://arxiv.org/abs/2206.12849)] [[(pseudo)Code](https://github.com/buraksatar/RoME_video_retrieval)] [[YouTube Ppt](https://www.youtube.com/watch?v=M7dHgv8fIkU)]

# Research during Master's Study

<img src="https://buraksatar.github.io/images/icann'18.png" alt="Detection and classification method" width="250"/> \\
**Deep Learning Based Vehicle Make-Model Classification** \\
**Burak Satar**, Ahmet Emir Dirik \\
ICANN 2018 Full Paper (Oral presentation) \\
[[arXiv](https://arxiv.org/abs/1809.00953)] [[Code](https://github.com/buraksatar/car-detection-model-prediction)]

<span style="color:blue"> -------------------------------------------------------------------------------------------------- </span>

# Previous News
* 12/2024: Successfully defended my PhD Thesis.
* 05/2024: Volunteered at ACM Web Conference.
* 10/2023: Visited [MaVi Research Group](https://uob-mavi.github.io/), University of Bristol, for three months under the supervision of [Dr Michael Wray](https://mwray.github.io/) on video corpus moment retrieval.
* 05/2023: A poster presentation at [Singapore Vision Day](https://www.comp.nus.edu.sg/~leegh/svd/) at NUS.
* 07/2022: Attended [CIFAR DLRL Summer School](https://dlrl.ca/).
* 06/2022: 3rd Place Award in EPIC-Kitchens [Multi-Instance Retrieval Challenge](https://epic-kitchens.github.io/2022), CVPR.
* 06/2022: Became a finalist in the [Three Minute Thesis](https://entuedu-my.sharepoint.com/:i:/g/personal/burak001_e_ntu_edu_sg/EQ0kK2wvx_NCozw2x-2rvDEBPNcEA507M4YHG-aEzVZgTA?e=ZuLwTs) (3MT) @ NTU, representing CCDS.  
* 01/2022: Successfully passed my Qualification Exam (QE).
* 12/2021: Volunteered in NeurIPS.
* 07/2021: Attended [PAISS AI Summer School](https://project.inria.fr/paiss/), and presented a poster.
* 2020: Started my PhD in the College of Computing and Data Science (CCDS), NTU.
* 08/2018: Successfully defended my MSc thesis. 
* 06/2018: Got [student travel award](https://e-nns.org/student-awards/winners-2018/) by European Neural Network Society to attend ICANN.
